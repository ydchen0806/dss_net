# ğŸ”§ ä»£ç æ”¹è¿›æ–¹æ¡ˆ - è§£å†³åˆ†è§£æ•ˆæœä¸ä½³çš„é—®é¢˜

## ğŸ“Š é—®é¢˜åˆ†æ

æ ¹æ®æ‚¨çš„è¯„ä¼°ç»“æœï¼š

| æ¨¡å‹ | Total NMSE (dB) | Total Loss | é—®é¢˜ |
|------|----------------|------------|------|
| **Baseline** | -25.00 | 0.0073 | âœ“ æ•ˆæœå¥½ |
| **Decomposer (æœ‰æ—¶é—´çº¦æŸ)** | -24.81 | 0.3629 | âœ— æ•ˆæœå·®ï¼ŒæŸå¤±é«˜50å€ |
| **Decomposer (æ— æ—¶é—´çº¦æŸ)** | -24.50 | 0.0373 | âœ— ä»æ¯”baselineå·® |

**æ ¸å¿ƒé—®é¢˜**ï¼š
1. åŠ¨æ€åˆ†é‡é‡å»ºå¾ˆå·®ï¼ˆ-12.81 dBï¼‰
2. æ€»æŸå¤±è¿‡é«˜ï¼ˆæ­£åˆ™åŒ–çº¦æŸè¿‡å¼ºï¼‰
3. åˆ†è§£æ¨¡å‹æ— æ³•å­¦åˆ°æœ‰æ•ˆçš„åˆ†ç¦»

---

## âœ… æ”¹è¿›æ–¹æ¡ˆ

### 1ï¸âƒ£ æŸå¤±å‡½æ•°æ”¹è¿› (loss.py)

#### é—®é¢˜ï¼šæ­£åˆ™åŒ–çº¦æŸè¿‡å¼ºï¼Œé˜»ç¢é‡å»º
```python
# âŒ åŸæ¥çš„é…ç½®
static_l1: 0.1              # è¿‡å¼º
dynamic_nuclear: 0.1        # è¿‡å¼º
sparsity_lambda: 0.001      # è¿‡å¼º
nuclear_lambda: 0.001       # è¿‡å¼º
```

#### æ”¹è¿›ï¼šå¤§å¹…å‡å¼±æ­£åˆ™åŒ–ï¼Œä¼˜å…ˆä¿è¯é‡å»ºè´¨é‡
```python
# âœ… æ”¹è¿›åçš„é…ç½®
static_l1: 0.01             # å‡å¼±10å€
dynamic_nuclear: 0.01       # å‡å¼±10å€
sparsity_lambda: 0.0001     # å‡å¼±10å€
nuclear_lambda: 0.0001      # å‡å¼±10å€
```

#### å…³é”®æ”¹è¿›ï¼š
- **æ›´å¹³è¡¡çš„é‡å»ºæƒé‡**ï¼š
  ```python
  static_mse: 1.0
  dynamic_mse: 2.0    # â†‘ åŠ¨æ€åˆ†é‡åŠ æƒï¼ˆåŸ1.0ï¼‰
  total_mse: 3.0      # â†‘ æ€»é‡å»ºæœ€é‡è¦ï¼ˆåŸ2.0ï¼‰
  ```

- **æ–°å¢åˆ†ç¦»è´¨é‡åº¦é‡**ï¼š
  ```python
  def _compute_separation_quality(static, dynamic):
      """ç¡®ä¿é™æ€å’ŒåŠ¨æ€çœŸçš„ä¸åŒï¼ˆä½ç›¸å…³æ€§ï¼‰"""
      correlation = compute_correlation(static, dynamic)
      return correlation  # è¶Šå°è¶Šå¥½
  ```

- **æ”¹è¿›æ—¶é—´çº¦æŸ**ï¼š
  ```python
  # âŒ åŸæ¥ï¼šè¿‡äºæ¿€è¿›
  return 1.0 / (variation + eps) - 1.0
  
  # âœ… æ”¹è¿›ï¼šæ¸©å’Œé¼“åŠ±
  target_variation = 0.01
  return F.relu(target_variation - variation)
  ```

---

### 2ï¸âƒ£ æ¨¡å‹æ¶æ„æ”¹è¿› (model.py)

#### é—®é¢˜ï¼šåŠ¨æ€åˆ†é‡decoderå®¹é‡ä¸è¶³

#### æ”¹è¿›ï¼šå¢å¼ºåŠ¨æ€åˆ†é‡decoder

```python
class UNetDecomposer:
    def __init__(self, use_attention=True):  # ğŸ†• æ·»åŠ attention
        # ğŸ†• Bottleneck attention
        self.bottleneck_attention = nn.Sequential(...)
        
        # ğŸ”§ åŠ¨æ€decoderä½¿ç”¨æ›´å®½çš„é€šé“ï¼ˆ1.5å€ï¼‰
        for i in range(depth):
            out_ch = ch // 2
            if i < depth // 2:
                out_ch = int(out_ch * 1.5)  # å‰é¢å‡ å±‚æ›´å®½
            self.up_dynamic.append(Up(ch, out_ch, ...))
        
        # ğŸ†• æ·»åŠ refinementå±‚
        self.dynamic_refine = DoubleConv(...)
```

**æ•ˆæœ**ï¼š
- åŠ¨æ€åˆ†é‡å‚æ•°é‡å¢åŠ çº¦30%
- Attentionå¸®åŠ©èšç„¦é‡è¦ç‰¹å¾
- Refinementæå‡è¾“å‡ºè´¨é‡

---

### 3ï¸âƒ£ è®­ç»ƒé…ç½®æ”¹è¿› (config.yaml)

#### é—®é¢˜ï¼šå­¦ä¹ ç‡åä½ï¼Œè®­ç»ƒä¸å……åˆ†

#### æ”¹è¿›ï¼š
```yaml
training:
  learning_rate: 1.0e-3      # â†‘ ä»5e-4æé«˜åˆ°1e-3
  epochs: 300                # â†‘ ä»100å¢åŠ åˆ°150
  
  scheduler:
    warmup_epochs: 5         # â†“ ä»10å‡å°‘åˆ°5
    min_lr: 1.0e-6           # æ›´ä½çš„æœ€å°å­¦ä¹ ç‡
  
  early_stopping:
    patience: 30             # â†‘ ä»20å¢åŠ åˆ°30
    min_delta: 0.0001        # æ›´ä¸¥æ ¼çš„åˆ¤æ–­
```

**åŸç†**ï¼š
- æ›´é«˜çš„å­¦ä¹ ç‡åŠ é€Ÿæ”¶æ•›
- æ›´é•¿çš„è®­ç»ƒæ—¶é—´è®©æ¨¡å‹å……åˆ†å­¦ä¹ 
- æ›´å®½æ¾çš„æ—©åœé¿å…è¿‡æ—©åœæ­¢

---

### 4ï¸âƒ£ æ¨¡å‹é…ç½®ä¼˜åŒ–

```yaml
model:
  base_channels: 64          # å¯ä»¥å°è¯•å¢åŠ åˆ°128
  dropout: 0.1               # â†“ ä»0.15é™ä½åˆ°0.1
  use_attention: true        # ğŸ†• å¯ç”¨attention
```

---

## ğŸ“ˆ é¢„æœŸæ”¹è¿›æ•ˆæœ

### æ”¹è¿›å‰ vs æ”¹è¿›åï¼š

| æŒ‡æ ‡ | åŸDecomposer | æ”¹è¿›Decomposer | ç›®æ ‡ |
|------|-------------|---------------|------|
| Total Loss | 0.363 | **< 0.01** | âœ“ æ¥è¿‘baseline |
| Total NMSE | -24.81 dB | **< -25 dB** | âœ“ ä¼˜äºbaseline |
| Dynamic NMSE | -12.81 dB | **< -20 dB** | âœ“ å¤§å¹…æå‡ |

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1ï¼šç›´æ¥æ›¿æ¢
```bash
# å¤‡ä»½åŸæ–‡ä»¶
cp loss.py loss_old.py
cp model.py model_old.py
cp config.yaml config_old.yaml
cp train.py train_old.py

# ä½¿ç”¨æ”¹è¿›ç‰ˆæœ¬
cp /path/to/improved/loss.py ./
cp /path/to/improved/model.py ./
cp /path/to/improved/config.yaml ./
cp /path/to/improved/train.py ./

# é‡æ–°è®­ç»ƒ
python train.py --config config.yaml
```

### æ–¹æ³•2ï¼šæ¸è¿›å¼æ”¹è¿›

å¦‚æœä¸ç¡®å®šæ•ˆæœï¼Œå¯ä»¥åˆ†æ­¥éªŒè¯ï¼š

#### æ­¥éª¤1ï¼šåªæ”¹lossï¼ˆæœ€é‡è¦ï¼‰
```bash
cp improved/loss.py ./
cp improved/config.yaml ./
python train.py --config config.yaml
```
**é¢„æœŸ**ï¼šLosså¤§å¹…ä¸‹é™ï¼Œæ¥è¿‘baseline

#### æ­¥éª¤2ï¼šå†æ”¹model
```bash
cp improved/model.py ./
cp improved/train.py ./
python train.py --config config.yaml
```
**é¢„æœŸ**ï¼šåŠ¨æ€åˆ†é‡NMSEæå‡

---

## ğŸ”¬ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

å¦‚æœä¸Šè¿°æ”¹è¿›åæ•ˆæœä»ä¸ç†æƒ³ï¼š

### 1. å¢åŠ æ¨¡å‹å®¹é‡
```yaml
model:
  base_channels: 128    # ä»64å¢åŠ åˆ°128
  depth: 5              # ä»4å¢åŠ åˆ°5
```

### 2. è°ƒæ•´batch sizeå’Œå­¦ä¹ ç‡
```yaml
training:
  batch_size: 8         # å‡å°batch size
  learning_rate: 5.0e-4 # ç›¸åº”é™ä½å­¦ä¹ ç‡
```

### 3. ä½¿ç”¨é¢„è®­ç»ƒç­–ç•¥
```python
# ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒbaselineæ¨¡å‹
python train.py --config config_baseunet.yaml

# ç¬¬äºŒé˜¶æ®µï¼šç”¨baselineæƒé‡åˆå§‹åŒ–encoder
# ç„¶åè®­ç»ƒåˆ†è§£æ¨¡å‹
```

### 4. æ•°æ®å¢å¼º
```yaml
data:
  augmentation:
    enabled: true
    spatial_masking:
      prob: 0.5          # å¢åŠ æ¦‚ç‡
      mask_ratio: 0.15   # å¢åŠ æ¯”ä¾‹
```

### 5. è°ƒæ•´temporalæƒé‡
å¦‚æœæ—¶é—´çº¦æŸè¿˜æ˜¯å½±å“æ€§èƒ½ï¼š
```yaml
loss:
  weights:
    static_temporal: 0.001   # è¿›ä¸€æ­¥é™ä½
    dynamic_temporal: 0.001  # è¿›ä¸€æ­¥é™ä½
```

---

## ğŸ’¡ å…³é”®åŸåˆ™

æ”¹è¿›çš„æ ¸å¿ƒæ€æƒ³ï¼š

1. **é‡å»ºè´¨é‡ä¼˜å…ˆ** - æ­£åˆ™åŒ–åªæ˜¯è¾…åŠ©
2. **å¹³è¡¡å¾ˆé‡è¦** - é™æ€å’ŒåŠ¨æ€åˆ†é‡æƒé‡è¦åˆç†
3. **çº¦æŸè¦æ¸©å’Œ** - è¿‡å¼ºçš„çº¦æŸä¼šé˜»ç¢å­¦ä¹ 
4. **ç»™æ¨¡å‹è¶³å¤Ÿå®¹é‡** - ç‰¹åˆ«æ˜¯åŠ¨æ€åˆ†é‡
5. **å……åˆ†è®­ç»ƒ** - ä¸è¦è¿‡æ—©åœæ­¢

---

## ğŸ“Š ç›‘æ§æŒ‡æ ‡

è®­ç»ƒæ—¶é‡ç‚¹å…³æ³¨ï¼š

```python
# å¸Œæœ›çœ‹åˆ°çš„è¶‹åŠ¿ï¼š
1. total_loss å¿«é€Ÿä¸‹é™åˆ° < 0.01
2. static_nmse_db å’Œ dynamic_nmse_db éƒ½ < -20 dB
3. total_nmse_db < -25 dB (ä¼˜äºbaseline)
4. separation_loss é€æ¸é™ä½ï¼ˆç›¸å…³æ€§é™ä½ï¼‰
```

---

## âœ… éªŒè¯æ”¹è¿›æ•ˆæœ

è®­ç»ƒå®Œæˆåï¼Œå¯¹æ¯”æ–°æ—§æ¨¡å‹ï¼š

```bash
# è¯„ä¼°æ–°æ¨¡å‹
python eval.py --checkpoint experiments/improved/best.pth

# å¯¹æ¯”ç»“æœ
# æœŸæœ›ï¼š
# - Total NMSE: ä»-24.81æå‡åˆ°-25ä»¥ä¸Š
# - Dynamic NMSE: ä»-12.81æå‡åˆ°-20ä»¥ä¸Š
# - Total Loss: ä»0.363é™ä½åˆ°0.01ä»¥ä¸‹
```

---

## ğŸ¯ æ€»ç»“

**æ”¹è¿›é‡ç‚¹æ’åº**ï¼š
1. ğŸ”¥ **æŸå¤±æƒé‡è°ƒæ•´**ï¼ˆæœ€é‡è¦ï¼Œç«‹ç«¿è§å½±ï¼‰
2. ğŸ”¥ **æ­£åˆ™åŒ–å‡å¼±**ï¼ˆå…³é”®ï¼Œé¿å…è¿‡çº¦æŸï¼‰
3. ğŸ”¥ **å­¦ä¹ ç‡æé«˜**ï¼ˆåŠ é€Ÿæ”¶æ•›ï¼‰
4. â­ **æ¨¡å‹å®¹é‡å¢åŠ **ï¼ˆæå‡ä¸Šé™ï¼‰
5. â­ **è®­ç»ƒæ—¶é—´å»¶é•¿**ï¼ˆå……åˆ†å­¦ä¹ ï¼‰

æŒ‰ç…§è¿™ä¸ªä¼˜å…ˆçº§é€æ­¥æ”¹è¿›ï¼Œæ•ˆæœåº”è¯¥èƒ½æ˜æ˜¾æå‡ï¼
