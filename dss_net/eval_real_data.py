"""
è¯„ä¼°çœŸå®æŠšä»™æ¹–æ•°æ®
- åŠ è½½DSS-Netæ¨¡å‹
- å¤„ç†çœŸå®æ•°æ®å¹¶è¿›è¡Œå»å™ª
- ç”Ÿæˆå¯è§†åŒ–ç»“æœ
"""

import os
import sys
import yaml
import torch
import torch.nn.functional as F
import numpy as np
import scipy.io as sio
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
from pathlib import Path
from datetime import datetime
import argparse

# å¯¼å…¥æ¨¡å‹
from model import UNetDecomposer


def load_model(checkpoint_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„DSS-Netæ¨¡å‹"""
    print(f"ğŸ“¦ Loading model from: {checkpoint_path}")
    
    # æ¨¡å‹é…ç½® (ä¸è®­ç»ƒæ—¶ä¸€è‡´)
    model = UNetDecomposer(
        in_channels=2,
        base_channels=64,
        depth=4,
        norm_type="batch",
        dropout=0.1,
        use_attention=True
    )
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()
    
    print(f"   âœ… Model loaded (epoch {checkpoint['epoch']}, val_loss: {checkpoint['best_val_loss']:.6f})")
    return model


def complex_to_tensor(complex_data):
    """å°†å¤æ•°æ•°ç»„è½¬æ¢ä¸º [2, H, W] å¼ é‡ (real, imag)"""
    real = np.real(complex_data)
    imag = np.imag(complex_data)
    tensor = np.stack([real, imag], axis=0)  # (2, H, W)
    return torch.from_numpy(tensor).float()


def tensor_to_complex(tensor):
    """å°† [2, H, W] å¼ é‡è½¬æ¢å›å¤æ•°æ•°ç»„"""
    if isinstance(tensor, torch.Tensor):
        tensor = tensor.cpu().numpy()
    real = tensor[0]
    imag = tensor[1]
    return real + 1j * imag


def normalize_power(tensor):
    """åŠŸç‡å½’ä¸€åŒ–"""
    power = torch.sqrt((tensor ** 2).mean())
    normalized = tensor / (power + 1e-8)
    return normalized, power


def denormalize(tensor, scale):
    """åå½’ä¸€åŒ–"""
    return tensor * scale


def pad_to_shape(tensor, target_h, target_w):
    """å°†è¾“å…¥é›¶å¡«å……åˆ°ç›®æ ‡å°ºå¯¸"""
    _, h, w = tensor.shape
    pad_h = target_h - h
    pad_w = target_w - w
    
    # (left, right, top, bottom)
    padding = (0, pad_w, 0, pad_h)
    return F.pad(tensor, padding, mode='constant', value=0), (h, w)


def crop_to_original(tensor, original_h, original_w):
    """è£å‰ªå›åŸå§‹å°ºå¯¸"""
    return tensor[:, :original_h, :original_w]


def compute_nmse(pred, target):
    """è®¡ç®—NMSE (dB)"""
    mse = np.mean(np.abs(pred - target) ** 2)
    signal_power = np.mean(np.abs(target) ** 2)
    nmse = 10 * np.log10(mse / (signal_power + 1e-10))
    return nmse


@torch.no_grad()
def process_real_data(model, data_path, device, save_dir, target_shape=(100, 150)):
    """
    å¤„ç†å•ä¸ªçœŸå®æ•°æ®æ–‡ä»¶
    
    Args:
        model: DSS-Netæ¨¡å‹
        data_path: .matæ–‡ä»¶è·¯å¾„
        device: è®¡ç®—è®¾å¤‡
        save_dir: ä¿å­˜ç›®å½•
        target_shape: æ¨¡å‹æœŸæœ›çš„è¾“å…¥å°ºå¯¸ (H, W)
    
    Returns:
        results: å¤„ç†ç»“æœå­—å…¸
    """
    print(f"\nğŸ“„ Processing: {os.path.basename(data_path)}")
    
    # åŠ è½½æ•°æ®
    data = sio.loadmat(data_path)
    est_h = data['est_h']  # (100, 120) complex
    original_shape = est_h.shape
    print(f"   Input shape: {original_shape}")
    
    # è½¬æ¢ä¸ºå¼ é‡
    input_tensor = complex_to_tensor(est_h)  # (2, 100, 120)
    
    # å¡«å……åˆ°ç›®æ ‡å°ºå¯¸
    input_padded, (orig_h, orig_w) = pad_to_shape(input_tensor, target_shape[0], target_shape[1])
    print(f"   Padded shape: {input_padded.shape}")
    
    # å½’ä¸€åŒ–
    input_norm, scale = normalize_power(input_padded)
    
    # æ·»åŠ batchç»´åº¦å¹¶ç§»åˆ°è®¾å¤‡
    input_batch = input_norm.unsqueeze(0).to(device)  # (1, 2, 100, 150)
    
    # æ¨¡å‹æ¨ç†
    output = model(input_batch)
    
    # æå–ç»“æœ
    pred_static = output['static'][0].cpu()  # (2, 100, 150)
    pred_dynamic = output['dynamic'][0].cpu()
    pred_total = output['total'][0].cpu()
    
    # åå½’ä¸€åŒ–
    pred_static = denormalize(pred_static, scale)
    pred_dynamic = denormalize(pred_dynamic, scale)
    pred_total = denormalize(pred_total, scale)
    
    # è£å‰ªå›åŸå§‹å°ºå¯¸
    pred_static = crop_to_original(pred_static, orig_h, orig_w)
    pred_dynamic = crop_to_original(pred_dynamic, orig_h, orig_w)
    pred_total = crop_to_original(pred_total, orig_h, orig_w)
    
    # è½¬æ¢å›å¤æ•°
    pred_static_complex = tensor_to_complex(pred_static)
    pred_dynamic_complex = tensor_to_complex(pred_dynamic)
    pred_total_complex = tensor_to_complex(pred_total)
    
    print(f"   Output shape: {pred_total_complex.shape}")
    
    # ä¿å­˜ç»“æœ
    results = {
        'input': est_h,
        'pred_static': pred_static_complex,
        'pred_dynamic': pred_dynamic_complex,
        'pred_total': pred_total_complex,
        'original_shape': original_shape
    }
    
    # ç”Ÿæˆå¯è§†åŒ–
    visualize_results(results, save_dir, os.path.basename(data_path).replace('.mat', ''))
    
    return results


def visualize_results(results, save_dir, prefix):
    """å¯è§†åŒ–å»å™ªç»“æœ"""
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    input_h = results['input']
    pred_static = results['pred_static']
    pred_dynamic = results['pred_dynamic']
    pred_total = results['pred_total']
    
    # 1. å¹…åº¦å›¾å¯¹æ¯”
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # è¾“å…¥ (å«å™ªå£°)
    ax = axes[0, 0]
    im = ax.imshow(np.abs(input_h), aspect='auto', cmap='viridis')
    ax.set_title('Input (Noisy Channel)', fontsize=12, fontweight='bold')
    ax.set_xlabel('Delay (samples)')
    ax.set_ylabel('Time (OFDM symbols)')
    plt.colorbar(im, ax=ax, fraction=0.046)
    
    # å»å™ªåæ€»ä¿¡é“
    ax = axes[0, 1]
    im = ax.imshow(np.abs(pred_total), aspect='auto', cmap='viridis')
    ax.set_title('DSS-Net Output (Denoised)', fontsize=12, fontweight='bold')
    ax.set_xlabel('Delay (samples)')
    ax.set_ylabel('Time (OFDM symbols)')
    plt.colorbar(im, ax=ax, fraction=0.046)
    
    # é™æ€åˆ†é‡
    ax = axes[1, 0]
    im = ax.imshow(np.abs(pred_static), aspect='auto', cmap='viridis')
    ax.set_title('Static Component', fontsize=12, fontweight='bold')
    ax.set_xlabel('Delay (samples)')
    ax.set_ylabel('Time (OFDM symbols)')
    plt.colorbar(im, ax=ax, fraction=0.046)
    
    # åŠ¨æ€åˆ†é‡
    ax = axes[1, 1]
    im = ax.imshow(np.abs(pred_dynamic), aspect='auto', cmap='viridis')
    ax.set_title('Dynamic Component', fontsize=12, fontweight='bold')
    ax.set_xlabel('Delay (samples)')
    ax.set_ylabel('Time (OFDM symbols)')
    plt.colorbar(im, ax=ax, fraction=0.046)
    
    plt.suptitle(f'DSS-Net Channel Decomposition: {prefix}', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(save_dir / f'{prefix}_magnitude.png', dpi=200, bbox_inches='tight')
    plt.close()
    
    # 2. æ—¶é—´åˆ‡ç‰‡å¯¹æ¯”
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    time_indices = [0, input_h.shape[0]//3, 2*input_h.shape[0]//3, input_h.shape[0]-1]
    
    for idx, t in enumerate(time_indices):
        ax = axes[idx // 2, idx % 2]
        ax.plot(np.abs(input_h[t, :]), 'b-', alpha=0.5, label='Input (Noisy)', linewidth=1)
        ax.plot(np.abs(pred_total[t, :]), 'r-', label='Denoised', linewidth=1.5)
        ax.plot(np.abs(pred_static[t, :]), 'g--', alpha=0.7, label='Static', linewidth=1)
        ax.plot(np.abs(pred_dynamic[t, :]), 'm--', alpha=0.7, label='Dynamic', linewidth=1)
        ax.set_title(f'Time Slice t={t}', fontsize=11, fontweight='bold')
        ax.set_xlabel('Delay (samples)')
        ax.set_ylabel('Magnitude')
        ax.legend(fontsize=8)
        ax.grid(alpha=0.3)
    
    plt.suptitle(f'Channel Impulse Response Comparison: {prefix}', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(save_dir / f'{prefix}_time_slices.png', dpi=200, bbox_inches='tight')
    plt.close()
    
    # 3. å»¶è¿Ÿåˆ‡ç‰‡å¯¹æ¯”
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    delay_indices = [0, input_h.shape[1]//4, input_h.shape[1]//2, 3*input_h.shape[1]//4]
    
    for idx, d in enumerate(delay_indices):
        ax = axes[idx // 2, idx % 2]
        ax.plot(np.abs(input_h[:, d]), 'b-', alpha=0.5, label='Input (Noisy)', linewidth=1)
        ax.plot(np.abs(pred_total[:, d]), 'r-', label='Denoised', linewidth=1.5)
        ax.plot(np.abs(pred_static[:, d]), 'g--', alpha=0.7, label='Static', linewidth=1)
        ax.plot(np.abs(pred_dynamic[:, d]), 'm--', alpha=0.7, label='Dynamic', linewidth=1)
        ax.set_title(f'Delay Slice d={d}', fontsize=11, fontweight='bold')
        ax.set_xlabel('Time (OFDM symbols)')
        ax.set_ylabel('Magnitude')
        ax.legend(fontsize=8)
        ax.grid(alpha=0.3)
    
    plt.suptitle(f'Temporal Variation Comparison: {prefix}', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(save_dir / f'{prefix}_delay_slices.png', dpi=200, bbox_inches='tight')
    plt.close()
    
    # 4. åŠŸç‡è°±åˆ†æ
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    
    # è¾“å…¥åŠŸç‡åˆ†å¸ƒ
    ax = axes[0]
    power_input = np.abs(input_h) ** 2
    ax.hist(power_input.flatten(), bins=50, alpha=0.7, color='blue', density=True)
    ax.set_title('Input Power Distribution', fontsize=11, fontweight='bold')
    ax.set_xlabel('Power')
    ax.set_ylabel('Density')
    ax.set_yscale('log')
    
    # é™æ€åˆ†é‡åŠŸç‡
    ax = axes[1]
    power_static = np.abs(pred_static) ** 2
    ax.hist(power_static.flatten(), bins=50, alpha=0.7, color='green', density=True)
    ax.set_title('Static Power Distribution', fontsize=11, fontweight='bold')
    ax.set_xlabel('Power')
    ax.set_ylabel('Density')
    ax.set_yscale('log')
    
    # åŠ¨æ€åˆ†é‡åŠŸç‡
    ax = axes[2]
    power_dynamic = np.abs(pred_dynamic) ** 2
    ax.hist(power_dynamic.flatten(), bins=50, alpha=0.7, color='magenta', density=True)
    ax.set_title('Dynamic Power Distribution', fontsize=11, fontweight='bold')
    ax.set_xlabel('Power')
    ax.set_ylabel('Density')
    ax.set_yscale('log')
    
    plt.suptitle(f'Power Analysis: {prefix}', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(save_dir / f'{prefix}_power_analysis.png', dpi=200, bbox_inches='tight')
    plt.close()
    
    print(f"   ğŸ“Š Visualizations saved to: {save_dir}")


def main():
    parser = argparse.ArgumentParser(description='Evaluate DSS-Net on Real Fuxian Lake Data')
    parser.add_argument('--checkpoint', type=str, 
                        default='/LSEM/user/chenyinda/code/signal_dy_static/dss_net/results_20251104_092511/full/Ablation2_FullImproved_UNetDecomposer_20251104_092515/checkpoints/best.pth',
                        help='Path to model checkpoint')
    parser.add_argument('--data_dir', type=str, 
                        default='/LSEM/user/chenyinda/code/signal_dy_static/sea_trial_data',
                        help='Path to real data directory')
    parser.add_argument('--output_dir', type=str, 
                        default='/LSEM/user/chenyinda/code/signal_dy_static/dss_net/real_data_results',
                        help='Output directory for results')
    parser.add_argument('--device', type=str, default='cuda:0',
                        help='Device to use')
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    
    print("\n" + "="*70)
    print("ğŸŒŠ DSS-Net Real Data Evaluation - Fuxian Lake Sea Trial")
    print("="*70)
    print(f"   Checkpoint: {args.checkpoint}")
    print(f"   Data Dir: {args.data_dir}")
    print(f"   Output Dir: {args.output_dir}")
    print(f"   Device: {device}")
    print("="*70)
    
    # åŠ è½½æ¨¡å‹
    model = load_model(args.checkpoint, device)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰æ•°æ®æ–‡ä»¶
    data_files = sorted(Path(args.data_dir).glob('*.mat'))
    print(f"\nğŸ“ Found {len(data_files)} data files")
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    all_results = []
    for data_path in data_files:
        try:
            results = process_real_data(
                model=model,
                data_path=str(data_path),
                device=device,
                save_dir=output_dir,
                target_shape=(100, 150)
            )
            all_results.append({
                'file': data_path.name,
                'results': results
            })
        except Exception as e:
            print(f"   âŒ Error processing {data_path.name}: {e}")
            import traceback
            traceback.print_exc()
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print("\n" + "="*70)
    print("ğŸ“‹ SUMMARY")
    print("="*70)
    
    for r in all_results:
        filename = r['file']
        results = r['results']
        
        # è®¡ç®—ä¸€äº›ç»Ÿè®¡é‡
        input_power = np.mean(np.abs(results['input']) ** 2)
        static_power = np.mean(np.abs(results['pred_static']) ** 2)
        dynamic_power = np.mean(np.abs(results['pred_dynamic']) ** 2)
        total_power = np.mean(np.abs(results['pred_total']) ** 2)
        
        static_ratio = static_power / (total_power + 1e-10) * 100
        dynamic_ratio = dynamic_power / (total_power + 1e-10) * 100
        
        print(f"\nğŸ“„ {filename}")
        print(f"   Input Power: {input_power:.6f}")
        print(f"   Output Power: {total_power:.6f}")
        print(f"   Static/Total: {static_ratio:.1f}%")
        print(f"   Dynamic/Total: {dynamic_ratio:.1f}%")
    
    # ä¿å­˜ç»“æœåˆ°.matæ–‡ä»¶
    save_path = output_dir / 'all_results.mat'
    save_data = {}
    for i, r in enumerate(all_results):
        prefix = r['file'].replace('.mat', '')
        save_data[f'{prefix}_input'] = r['results']['input']
        save_data[f'{prefix}_static'] = r['results']['pred_static']
        save_data[f'{prefix}_dynamic'] = r['results']['pred_dynamic']
        save_data[f'{prefix}_total'] = r['results']['pred_total']
    
    sio.savemat(str(save_path), save_data)
    print(f"\nğŸ’¾ Results saved to: {save_path}")
    
    print("\n" + "="*70)
    print("âœ… EVALUATION COMPLETE!")
    print("="*70 + "\n")


if __name__ == '__main__':
    main()

